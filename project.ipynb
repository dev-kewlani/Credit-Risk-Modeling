{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing and Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for year in range(2003, 2018):\n",
    "    for quarter in range(1, 5):\n",
    "        df = pd.read_csv(f\"/Users/admin/Downloads/LGD/data_files/{year}Q{quarter}.csv\")\n",
    "        data = pd.concat([data, df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['MI_TYPE'].isna()]['OLTV'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_fred(series_id):\n",
    "\n",
    "    api_key = '8ff9ccdccdab3eb09b6b671419842004'\n",
    "    url = f'https://api.stlouisfed.org/fred/series/observations?series_id={series_id}&api_key={api_key}&file_type=json'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        df = pd.DataFrame(data['observations'])\n",
    "        df['date'] = pd.to_datetime(df['date'])  # Convert date to datetime format\n",
    "        df = df[df['value'] != '.']\n",
    "        df['value'] = df['value'].astype(float)  # Convert value to float\n",
    "        df = df[['date', 'value']]\n",
    "        df.columns = ['date', series_id]\n",
    "        df.rename(columns={'value': series_id}, inplace=True)\n",
    "        df['date_mm'] = pd.to_datetime(df['date']).dt.month\n",
    "        df['date_yy'] = pd.to_datetime(df['date']).dt.year\n",
    "        df['custom_date_format'] = df['date_mm'].astype(str).str[:] + df['date_yy'].astype(str).str[:]\n",
    "        df = df.drop_duplicates(subset='custom_date_format', keep='first')\n",
    "    else:\n",
    "        print(f\"Error fetching data: {response.status_code}\")\n",
    "    \n",
    "    return df[['custom_date_format', series_id]]\n",
    "\n",
    "def convert_to_custom_date(df):\n",
    "    value = df.columns.values[1]\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])  # Convert date to datetime format\n",
    "    df.loc[:,df.columns.values[1]] = df[df.columns.values[1]].astype(float)  # Convert value to float\n",
    "    df['date_mm'] = pd.to_datetime(df['DATE']).dt.month\n",
    "    df['date_yy'] = pd.to_datetime(df['DATE']).dt.year\n",
    "    df['custom_date_format'] = df['date_mm'].astype(str).str[:] + df['date_yy'].astype(str).str[:]\n",
    "    return df[['custom_date_format', value]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp = get_data_fred('UNRATE')\n",
    "ir = get_data_fred('FEDFUNDS')\n",
    "cpi = get_data_fred('CPIAUCNS')\n",
    "cpi['inflation'] = (cpi['CPIAUCNS'].pct_change())*100\n",
    "vix = get_data_fred('VIXCLS')\n",
    "personal_savings_rate = get_data_fred('PSAVERT')\n",
    "housing_starts_data = get_data_fred('HOUST')\n",
    "\n",
    "hpi_master = pd.read_csv(\"/Users/admin/Downloads/LGD/Loss-Severity-Modeling-of-Single-Family-Residential-Mortgage-Loans-main/MacroEconomicVariables/HPI_master.csv\")\n",
    "national_hpi = pd.read_csv(\"/Users/admin/Downloads/LGD/Loss-Severity-Modeling-of-Single-Family-Residential-Mortgage-Loans-main/MacroEconomicVariables/National_HPI.csv\")\n",
    "state_hpi = pd.read_csv(\"/Users/admin/Downloads/LGD/Loss-Severity-Modeling-of-Single-Family-Residential-Mortgage-Loans-main/MacroEconomicVariables/States_HPI.csv\")\n",
    "\n",
    "national_hpi = convert_to_custom_date(national_hpi)\n",
    "national_hpi = national_hpi.drop_duplicates(subset='custom_date_format', keep='first')\n",
    "national_hpi['custom_date_format'] = national_hpi['custom_date_format'].astype(float)\n",
    "\n",
    "states_hpi = pd.read_csv(\"/Users/admin/Downloads/LGD/Loss-Severity-Modeling-of-Single-Family-Residential-Mortgage-Loans-main/MacroEconomicVariables/States_HPI.csv\")\n",
    "mortgage_rate = pd.read_csv(\"/Users/admin/Downloads/LGD/Loss-Severity-Modeling-of-Single-Family-Residential-Mortgage-Loans-main/MacroEconomicVariables/Mortgage.csv\")\n",
    "mortgage_rate = convert_to_custom_date(mortgage_rate)\n",
    "mortgage_rate = mortgage_rate.drop_duplicates(subset='custom_date_format', keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_hpi.columns = [state_hpi.columns[0]] + [col[:2] for col in state_hpi.columns[1:]]\n",
    "state_hpi['date_mm'] = pd.to_datetime(state_hpi['DATE']).dt.month\n",
    "state_hpi['date_yy'] = pd.to_datetime(state_hpi['DATE']).dt.year\n",
    "state_hpi['custom_date_format'] = state_hpi['date_mm'].astype(str).str[:] + state_hpi['date_yy'].astype(str).str[:]\n",
    "state_hpi.drop(columns = ['DATE', 'date_mm', 'date_yy'], inplace=True)\n",
    "state_hpi = state_hpi.sort_values(by='custom_date_format')\n",
    "state_hpi.columns[1:]\n",
    "state_hpi_copy = state_hpi.copy()\n",
    "state_hpi_copy = pd.melt(state_hpi_copy, id_vars='custom_date_format', value_name='State_HPI', var_name='STATE')\n",
    "state_hpi_copy['custom_date_format'] = state_hpi_copy['custom_date_format'].astype(float)\n",
    "state_hpi_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_hpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macros = [ir, vix, personal_savings_rate, housing_starts_data, mortgage_rate]\n",
    "all_macros = unemp.merge(cpi, on='custom_date_format', how='outer')\n",
    "for macro in macros:\n",
    "    all_macros = all_macros.merge(macro, on='custom_date_format', how='outer')\n",
    "all_macros['year'] = all_macros['custom_date_format'].str[-4:]\n",
    "req_macro_data = all_macros[(all_macros['year'].astype(int) > 1990) & (all_macros['year'].astype(int) < 2023)]\n",
    "req_macro_data.drop(columns='year',inplace=True)\n",
    "req_macro_data['custom_date_format'] = req_macro_data['custom_date_format'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_hpi_copy_orig = state_hpi_copy.copy()\n",
    "state_hpi_copy_zb = state_hpi_copy.copy()\n",
    "state_hpi_copy_orig.columns = [f'{col}_at_orig' for col in state_hpi_copy_orig.columns]\n",
    "state_hpi_copy_zb.columns = [f'{col}_at_zb' for col in state_hpi_copy_zb.columns]\n",
    "\n",
    "national_hpi_orig = national_hpi.copy()\n",
    "national_hpi_zb = national_hpi.copy()\n",
    "national_hpi_orig.columns = [f'{col}_at_orig' for col in national_hpi_orig.columns]\n",
    "national_hpi_zb.columns = [f'{col}_at_zb' for col in national_hpi_zb.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge macro variables on ZB_DTE because thats the date of observance of data and merge HPI on orig date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = data.merge(req_macro_data, how='left', left_on='ZB_DTE', right_on='custom_date_format')\n",
    "\n",
    "final_data = final_data.merge(state_hpi_copy_orig, how='left', left_on= ['ORIG_DATE', 'STATE'], right_on=['custom_date_format_at_orig', 'STATE_at_orig'])\n",
    "final_data = final_data.merge(state_hpi_copy_zb, how='left', left_on= ['ZB_DTE', 'STATE'], right_on=['custom_date_format_at_zb', 'STATE_at_zb'])\n",
    "\n",
    "final_data = final_data.merge(national_hpi_orig, how='left', left_on='ORIG_DATE', right_on='custom_date_format_at_orig')\n",
    "final_data = final_data.merge(national_hpi_zb, how='left', left_on='ZB_DTE', right_on='custom_date_format_at_zb') #CSUSHPISA\n",
    "\n",
    "final_data['HPI'] = np.where(\n",
    "    (final_data['State_HPI_at_zb'].notnull() & final_data['State_HPI_at_orig'].notnull()),\n",
    "    ((final_data['State_HPI_at_zb'] / final_data['State_HPI_at_orig']) - 1)*100,\n",
    "    ((final_data['CSUSHPISA_at_zb'] / final_data['CSUSHPISA_at_orig']) - 1)*100\n",
    ")\n",
    "final_data = final_data.sort_values(by='ZB_DTE')\n",
    "data['loan_id'] = data['LOAN_ID']\n",
    "final_data = final_data.set_index('LOAN_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = final_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle Missing Data and Prepare entire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_all_missing(data):\n",
    "    missing = data.isna().sum()\n",
    "    all_vals_missing_cols = missing[missing == len(data)].index.tolist()\n",
    "    data.drop(columns=all_vals_missing_cols, inplace=True)\n",
    "    return data\n",
    "\n",
    "def handle_other_missing(data):\n",
    "    custom_date_col = data.filter(like='custom_date')\n",
    "    data.drop(columns = custom_date_col.columns, inplace=True)\n",
    "    data['CSCORE_C'].fillna(data['CSCORE_B'], inplace=True)\n",
    "    data['CURR_RATE'].fillna(data['MORTGAGE30US'], inplace=True) #fill current rate with 30yr mortgage rate\n",
    "    # data['State_HPI'].fillna(data['nationalHPI'], inplace=True)\n",
    "    data['OCLTV'].fillna(data['OLTV'], inplace=True)\n",
    "    data['NUM_BO'].fillna(math.floor(data['NUM_BO'].mean()), inplace=True)\n",
    "    data.dropna(subset=['DTI', 'CSCORE_B', 'PPMT_FLG', 'FORECLOSURE_DATE', 'LAST_PAID_INSTALLMENT_DATE'], inplace=True)\n",
    "    data['FIRST_FLAG'].fillna('N', inplace=True)\n",
    "    data['MI_PCT'].fillna(data['MI_PCT'].median(), inplace=True)\n",
    "    data['MI_TYPE'].fillna('N', inplace=True) #if LTV > 0.8, then MI_TYPE will be yes, --> in glossary states N, so not filling with Yes\n",
    "    data['MOD_FLAG'].fillna('N', inplace=True)\n",
    "    data['DISPOSITION_DATE'].fillna(data['FORECLOSURE_DATE'], inplace=True)\n",
    "    cols = (data.filter(like='COSTS').columns).tolist() + (data.filter(like='PROCEEDS').columns).tolist()\n",
    "    main_cols = cols + ['FORECLOSURE_PRINCIPAL_WRITE_OFF_AMOUNT', 'MISCELLANEOUS_HOLDING_EXPENSES_AND_CREDITS', 'ASSOCIATED_TAXES_FOR_HOLDING_PROPERTY', 'NON_INTEREST_BEARING_UPB', 'PRINCIPAL_FORGIVENESS_AMOUNT']\n",
    "    data[main_cols] = data[main_cols].fillna(0)\n",
    "    data.filter(like='COSTS').fillna(0, inplace=True)\n",
    "    data.filter(like='PROCEEDS').fillna(0, inplace=True)\n",
    "    data.drop(columns=['PRODUCT', 'PPMT_FLG', 'IO', 'HOMEREADY_PROGRAM_INDICATOR', 'RELOCATION_MORTGAGE_INDICATOR', 'STATE_at_orig', 'STATE_at_zb', 'State_HPI_at_orig', 'State_HPI_at_zb',\n",
    "                       'HIGH_BALANCE_LOAN_INDICATOR', 'HIGH_LOAN_TO_VALUE_HLTV_REFINANCE_OPTION_INDICATOR',\n",
    "                       'CURRENT_UPB', 'TOT_SCHD_PRNCPL', 'PROPERTY_INSPECTION_WAIVER_INDICATOR', 'FORBEARANCE_INDICATOR', 'ADR_TYPE', 'ADR_COUNT', 'ADR_UPB'], inplace=True)\n",
    "    return data\n",
    "\n",
    "data = handle_all_missing(data)\n",
    "data = handle_other_missing(data)\n",
    "date_cols = ['ORIG_DATE', 'LAST_PAID_INSTALLMENT_DATE', 'FORECLOSURE_DATE', 'DISPOSITION_DATE', 'FIRST_PAY', 'ZB_DTE', 'ACT_PERIOD']\n",
    "for date_col in date_cols:\n",
    "    data[date_col] = data[date_col].astype(int).astype(str)\n",
    "    data[date_col+'_month'] =  pd.to_numeric(data[date_col].str[:-4], errors='coerce')\n",
    "    data[date_col+'_year'] =  pd.to_numeric(data[date_col].str[-4:], errors='coerce')\n",
    "data.drop(['ORIG_DATE', 'LAST_PAID_INSTALLMENT_DATE', 'FORECLOSURE_DATE', 'DISPOSITION_DATE', 'FIRST_PAY', 'ACT_PERIOD'], axis= 1, inplace=True)\n",
    "data = data[data['LAST_UPB'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Zero_Bal_Code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['INT_COST'] =  (data['DISPOSITION_DATE_year'] * 12 + data['DISPOSITION_DATE_month']- \\\n",
    "                    data['LAST_PAID_INSTALLMENT_DATE_year'] * 12 - data['LAST_PAID_INSTALLMENT_DATE_month']) * \\\n",
    "                    (((data['CURR_RATE'] / 100) - 0.0035) / 12) * (data['LAST_UPB'] - data['NON_INTEREST_BEARING_UPB'])\n",
    "data['INT_COST'] = data['INT_COST'].fillna(0)\n",
    "data['INT_COST'] = data['INT_COST'].apply(lambda x: x if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['loss'] = (data['LAST_UPB'] + \\\n",
    "               data['FORECLOSURE_COSTS'] + \\\n",
    "               data['PROPERTY_PRESERVATION_AND_REPAIR_COSTS'] + \\\n",
    "               data['ASSET_RECOVERY_COSTS'] + \\\n",
    "               data['MISCELLANEOUS_HOLDING_EXPENSES_AND_CREDITS'] + \\\n",
    "               data['ASSOCIATED_TAXES_FOR_HOLDING_PROPERTY'] + \\\n",
    "               data['PRINCIPAL_FORGIVENESS_AMOUNT'] + \\\n",
    "               data['INT_COST'] - \\\n",
    "               data['NET_SALES_PROCEEDS'] - \\\n",
    "               data['CREDIT_ENHANCEMENT_PROCEEDS'] - \\\n",
    "               data['OTHER_FORECLOSURE_PROCEEDS'])\n",
    "data['loss'] = data['loss'].round(2)\n",
    "# data['loan_id'] = data['LOAN_ID']\n",
    "# data.set_index('LOAN_ID',inplace=True)\n",
    "data['lgd'] = (data['loss']/data['ORIG_UPB'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lgd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the loss cols in conjunction with other cols, something like median of costs wrt to state and then use that value as a predictor for LGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_loss_df = data[(data['lgd'] < -200) | (data['lgd'] > 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outlier_loss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(outlier_loss_df.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the histogram\n",
    "data['lgd'].hist(bins=200)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Distribution of Loss Given Default (LGD)')\n",
    "plt.xlabel('LGD Values')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.replace(' ', '_')\n",
    "data['SELLER'].replace(' ', '_', regex=True, inplace=True)\n",
    "data.drop('OCLTV', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cols = ['FORECLOSURE_COSTS', 'PROPERTY_PRESERVATION_AND_REPAIR_COSTS', 'ASSET_RECOVERY_COSTS', 'MISCELLANEOUS_HOLDING_EXPENSES_AND_CREDITS'\n",
    "             , 'ASSOCIATED_TAXES_FOR_HOLDING_PROPERTY', 'PRINCIPAL_FORGIVENESS_AMOUNT', 'INT_COST', 'NET_SALES_PROCEEDS', 'CREDIT_ENHANCEMENT_PROCEEDS'\n",
    "             , 'REPURCHASES_MAKE_WHOLE_PROCEEDS', 'OTHER_FORECLOSURE_PROCEEDS', 'Zero_Bal_Code', 'NON_INTEREST_BEARING_UPB'\n",
    "             , 'FORECLOSURE_PRINCIPAL_WRITE_OFF_AMOUNT', 'FORECLOSURE_DATE_month', 'FORECLOSURE_DATE_year'\n",
    "             , 'DISPOSITION_DATE_month', 'DISPOSITION_DATE_year', 'ZB_DTE_month', 'ZB_DTE_year', 'loss', 'lgd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_prior_2009 = data[data['ORIG_DATE_year'] <= 2009]\n",
    "orig_after_2009 = data[data['ORIG_DATE_year'] > 2009]\n",
    "zb_prior_2009 = data[data['ZB_DTE_year'] <= 2009]\n",
    "zb_after_2009 = data[data['ZB_DTE_year'] > 2009]\n",
    "\n",
    "statewise_orig_prior_2009 = pd.DataFrame(orig_prior_2009.groupby(['STATE'])['lgd'].mean())\n",
    "statewise_orig_after_2009 = pd.DataFrame(orig_after_2009.groupby(['STATE'])['lgd'].mean())\n",
    "statewise_zb_prior_2009 = pd.DataFrame(zb_prior_2009.groupby(['STATE'])['lgd'].mean())\n",
    "statewise_zb_after_2009 = pd.DataFrame(zb_after_2009.groupby(['STATE'])['lgd'].mean())\n",
    "\n",
    "statewise_count = pd.DataFrame(data.groupby(['STATE'])['lgd'].count()).reset_index()\n",
    "statewise_count.columns = ['STATE', 'count']\n",
    "statewise_meanLGD = pd.DataFrame(data.groupby(['STATE'])['lgd'].mean()).reset_index()\n",
    "statewise_meanLGD.columns = ['STATE', 'lgd']\n",
    "# statewise_count['STATE'] = statewise_count.index\n",
    "# statewise_meanLGD['STATE'] = statewise_meanLGD.index\n",
    "statewiseCountAndMean = statewise_count.merge(statewise_meanLGD, on='STATE')\n",
    "# statewise_lgd.sort_values(by='lgd', ascending=False, inplace=True)\n",
    "# # statewise_lgd.plot(kind='bar')\n",
    "# statewise_lgd\n",
    "# plt.figure(figsize = (25,20))\n",
    "# statewise_orig_prior_2009.sort_values(by='lgd', ascending=False).plot(kind='bar')\n",
    "# statewise_orig_after_2009.sort_values(by='lgd', ascending=False).plot(kind='bar')\n",
    "# df_sorted = statewiseCountAndMean.sort_values(by='lgd')\n",
    "sorted_indices = np.argsort(statewiseCountAndMean['lgd'])[::-1]\n",
    "states = [statewiseCountAndMean['STATE'].iloc[i] for i in sorted_indices]\n",
    "counts = [statewiseCountAndMean['count'].iloc[i] for i in sorted_indices]\n",
    "lgds = [statewiseCountAndMean['lgd'].iloc[i] for i in sorted_indices]\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Bar plot for count (left axis)\n",
    "ax1.bar(states, counts, color='red', alpha=1, label='Number of Loans')\n",
    "ax1.set_xlabel('State')\n",
    "ax1.set_ylabel('Number of Loans', color='red')\n",
    "ax1.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "\n",
    "# Line plot for mean LGD (right axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(states, lgds, color='black', marker='o', label='Mean LGD')\n",
    "ax2.set_ylabel('Mean LGD (%)', color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add legends and titles\n",
    "fig.suptitle('Number of Loans and Mean LGD by State')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = data[data['STATE'] == 'VI']\n",
    "vi_analysis = pd.DataFrame(vi.groupby(['ORIG_DATE_year', 'CSCORE_B', 'OLTV', 'ORIG_RATE', 'CURR_RATE', 'PURPOSE', 'DTI', 'OCC_STAT', 'MI_TYPE', 'MI_PCT', 'HPI'])['lgd'].mean()).reset_index().sort_values(by='lgd', ascending=False)\n",
    "vi_analysis.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = data[data['STATE'] == 'TX']\n",
    "nj = data[data['STATE'] == 'NJ']\n",
    "tx_analysis = pd.DataFrame(tx.groupby(['ORIG_DATE_year', 'ZB_DTE', 'HPI'])['lgd'].mean()).reset_index().sort_values(by='lgd', ascending=False)\n",
    "tx_analysis\n",
    "nj_analysis = pd.DataFrame(nj.groupby(['ORIG_DATE_year', 'ZB_DTE', 'HPI'])['lgd'].mean()).reset_index().sort_values(by='lgd', ascending=False)\n",
    "nj_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CSCORE_B'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(statewiseCountAndMean['lgd'])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statewiseCountAndMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (data.filter(like='COST').columns).tolist() + (data.filter(like='PROCEEDS').columns).tolist()\n",
    "main_cols = cols + ['FORECLOSURE_PRINCIPAL_WRITE_OFF_AMOUNT', 'MISCELLANEOUS_HOLDING_EXPENSES_AND_CREDITS', 'ASSOCIATED_TAXES_FOR_HOLDING_PROPERTY', 'NON_INTEREST_BEARING_UPB', 'PRINCIPAL_FORGIVENESS_AMOUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2009 = data[data['ZB_DTE'] <= '122009']\n",
    "data_2009_2017 = data[data['ZB_DTE'] > '122009']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the histogram\n",
    "data_2009['lgd'].hist(bins=200)\n",
    "# data_2009[(data_2009['ZB_DTE'] > '122005') & (data_2009['ZB_DTE'] < '122008')]['lgd'].hist(bins=200)\n",
    "\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Distribution of Loss Given Default (LGD) before 2009')\n",
    "plt.xlabel('LGD Values')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the histogram\n",
    "# data_2009_2017[(data_2009_2017['ZB_DTE'] > '122008') & (data_2009_2017['ZB_DTE'] < '122011')]['lgd'].hist(bins=200)\n",
    "data_2009_2017['lgd'].hist(bins=200)\n",
    "\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Distribution of Loss Given Default (LGD) after 2009')\n",
    "plt.xlabel('LGD Values')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data)\n",
    "train_data = data.iloc[:450000]\n",
    "test_data = data.iloc[450000:]\n",
    "train_data_2009 = data_2009.iloc[:100000]\n",
    "test_data_2009 = data_2009.iloc[100000:]\n",
    "train_data_2009_2017 = data_2009_2017.iloc[:350000]\n",
    "test_data_2009_2017 = data_2009_2017.iloc[350000:]\n",
    "\n",
    "y_test_2009, y_test_2009_2017  = test_data_2009['lgd'], test_data_2009_2017['lgd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_all = test_data['lgd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (data.filter(like='COST').columns).tolist() + (data.filter(like='PROCEEDS').columns).tolist()\n",
    "main_cols = cols + ['FORECLOSURE_PRINCIPAL_WRITE_OFF_AMOUNT', 'MISCELLANEOUS_HOLDING_EXPENSES_AND_CREDITS', 'ASSOCIATED_TAXES_FOR_HOLDING_PROPERTY', 'NON_INTEREST_BEARING_UPB', 'PRINCIPAL_FORGIVENESS_AMOUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_indicator_for_test_9 = pd.DataFrame(train_data_2009.groupby(['STATE'])['FORECLOSURE_COSTS'].mean())\n",
    "loss_indicator_for_test_after = pd.DataFrame(train_data_2009_2017.groupby(['STATE'])['FORECLOSURE_COSTS'].mean())\n",
    "loss_indicator_for_test_all = pd.DataFrame(train_data.groupby(['STATE'])['FORECLOSURE_COSTS'].mean())\n",
    "\n",
    "\n",
    "main_cols=main_cols[1:]\n",
    "for col in main_cols:\n",
    "    x_all = pd.DataFrame(train_data.groupby(['STATE'])[col].mean())\n",
    "    x_9 = pd.DataFrame(train_data_2009.groupby(['STATE'])[col].mean())\n",
    "    x_after = pd.DataFrame(train_data_2009_2017.groupby(['STATE'])[col].mean())\n",
    "    loss_indicator_for_test_all = pd.merge(loss_indicator_for_test_all, x_all, how='left', on = 'STATE')\n",
    "    loss_indicator_for_test_9 = pd.merge(loss_indicator_for_test_9, x_9, how='left', on = 'STATE')\n",
    "    loss_indicator_for_test_after = pd.merge(loss_indicator_for_test_after, x_after, how='left', on = 'STATE')\n",
    "\n",
    "X_test = pd.merge(test_data.drop(columns=loss_cols), loss_indicator_for_test_all, how='left', on='STATE')\n",
    "object_col_df = X_test.select_dtypes(include=['object'])\n",
    "object_col_df.head()\n",
    "X_test = pd.get_dummies(X_test, columns=object_col_df.drop(columns=['ZB_DTE', 'SELLER', 'DLQ_STATUS']).columns, dtype='int')\n",
    "\n",
    "X_test_2009 = pd.merge(test_data_2009.drop(columns=loss_cols), loss_indicator_for_test_9, how='left', on='STATE')\n",
    "object_col_df = X_test_2009.select_dtypes(include=['object'])\n",
    "object_col_df.head()\n",
    "X_test_2009 = pd.get_dummies(X_test_2009, columns=object_col_df.drop(columns=['ZB_DTE', 'SELLER', 'DLQ_STATUS']).columns, dtype='int')\n",
    "\n",
    "X_test_2009_2017 = pd.merge(test_data_2009_2017.drop(columns=loss_cols), loss_indicator_for_test_after, how = 'left', on='STATE')\n",
    "object_col_df = X_test_2009_2017.select_dtypes(include=['object'])\n",
    "object_col_df.head()\n",
    "X_test_2009_2017 = pd.get_dummies(X_test_2009_2017, columns=object_col_df.drop(columns=['ZB_DTE', 'SELLER', 'DLQ_STATUS']).columns, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def run_linear_regression_model(window_size, test_size, train_data):\n",
    "\n",
    "    n = len(train_data)\n",
    "\n",
    "    # Lists to store metrics and lin_models\n",
    "    mse_list = []\n",
    "    r2_list = []\n",
    "    mape_list = []\n",
    "    test_and_preds_list = []\n",
    "    mae_list = []\n",
    "\n",
    "    # Sliding window training loop\n",
    "    for start in range(window_size, n, test_size):\n",
    "        training_1 = train_data.iloc[:start]  # Define the training window\n",
    "        dev_1 = train_data.iloc[start:start+test_size]  # Define the next test set\n",
    "\n",
    "        # Create loss indicator for the training data\n",
    "        loss_indicator_for_train = pd.DataFrame(training_1.groupby(['STATE'])['FORECLOSURE_COSTS'].mean())\n",
    "\n",
    "        # Iterate over main columns to calculate mean and merge for training data\n",
    "        loss_indicator_for_training_1 = loss_indicator_for_train.copy()  # Initialize the loss indicator\n",
    "        for col in main_cols:\n",
    "            x = pd.DataFrame(training_1.groupby(['STATE'])[col].mean())\n",
    "            loss_indicator_for_training_1 = pd.merge(loss_indicator_for_training_1, x, how='left', on='STATE')\n",
    "\n",
    "        # Apply the same transformations on both training and test data\n",
    "        X_training_1 = pd.merge(training_1.drop(columns=loss_cols), loss_indicator_for_training_1, how='left', on='STATE')\n",
    "        y_training_1 = training_1['lgd']\n",
    "\n",
    "        X_dev_1 = pd.merge(dev_1.drop(columns=loss_cols), loss_indicator_for_training_1, how='left', on='STATE')\n",
    "        y_dev_1 = dev_1['lgd']\n",
    "\n",
    "        # Convert categorical features using one-hot encoding (excluding 'ZB_DTE' and 'SELLER')\n",
    "        object_cols = X_training_1.select_dtypes(include=['object']).columns.drop(['ZB_DTE', 'SELLER', 'DLQ_STATUS'])\n",
    "        X_training_1 = pd.get_dummies(X_training_1, columns=object_cols, dtype='int')\n",
    "        X_dev_1 = pd.get_dummies(X_dev_1, columns=object_cols, dtype='int')\n",
    "\n",
    "        X_training_1.drop(columns=['ZB_DTE', 'SELLER', 'DLQ_STATUS'], inplace=True)\n",
    "        X_dev_1.drop(columns=['ZB_DTE', 'SELLER', 'DLQ_STATUS'], inplace=True)\n",
    "\n",
    "        # Ensure train and test have the same columns after encoding\n",
    "        X_training_1, X_dev_1 = X_training_1.align(X_dev_1, join='left', axis=1, fill_value=0)\n",
    "\n",
    "        # Initialize and train the Linear Regression lin_model\n",
    "        lin_model = LinearRegression()\n",
    "        lin_model.fit(X_training_1, y_training_1)\n",
    "\n",
    "        y_pred = lin_model.predict(X_dev_1)\n",
    "        y_pred_series = pd.Series(y_pred, index=y_dev_1.index)\n",
    "        test_and_preds = pd.concat([y_dev_1, y_pred_series], axis=1)\n",
    "        test_and_preds.columns = ['actual', 'predicted']\n",
    "        test_and_preds_list.append(test_and_preds)\n",
    "\n",
    "        # Calculate MSE, R-squared, MAPE, and MAE\n",
    "        mse = mean_squared_error(y_dev_1, y_pred)\n",
    "        r2 = r2_score(y_dev_1, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_dev_1, y_pred)\n",
    "        mae = mean_absolute_error(y_dev_1, y_pred)\n",
    "        \n",
    "        # Store metrics and lin_model\n",
    "        mse_list.append(mse)\n",
    "        r2_list.append(r2)\n",
    "        mape_list.append(mape)\n",
    "        mae_list.append(mae)\n",
    "\n",
    "        print(f\"Mean Squared Error for this window (start {start}): {mse}\")\n",
    "        print(f\"Mean Absolute Error for this window (start {start}): {mae}\")\n",
    "        print(f\"Mean % Error for this window (start {start}): {mape}\")\n",
    "        print(f\"R² for this window (start {start}): {r2}\")\n",
    "\n",
    "    return test_and_preds_list, mse_list, r2_list, mape_list, mae_list, lin_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_preds_list_9, mse_list_9, r2_list_9, mape_list_9, mae_list_9, lin_model_9 = run_linear_regression_model(20000, 10000, train_data_2009)\n",
    "test_and_preds_list_9_after, mse_list_9_after, r2_list_9_after, mape_list_9_after, mae_list_9_after, lin_model_after = run_linear_regression_model(50000, 50000, train_data_2009_2017)\n",
    "test_and_preds_all, mse_list_all, r2_list_all, mape_list_all, mae_list_all, lin_model_all = run_linear_regression_model(100000, 50000, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine predictions for each time period into a DataFrame\n",
    "lin_df_preds = pd.DataFrame({\n",
    "    \"lin_actual_9\": pd.concat([df[\"actual\"] for df in test_and_preds_list_9], axis=0).reset_index(drop=True),\n",
    "    \"lin_predicted_9\": pd.concat([df[\"predicted\"] for df in test_and_preds_list_9], axis=0).reset_index(drop=True),\n",
    "    \"lin_actual_after\": pd.concat([df[\"actual\"] for df in test_and_preds_list_9_after], axis=0).reset_index(drop=True),\n",
    "    \"lin_predicted_after\": pd.concat([df[\"predicted\"] for df in test_and_preds_list_9_after], axis=0).reset_index(drop=True),\n",
    "    \"lin_actual_all\": pd.concat([df[\"actual\"] for df in test_and_preds_all], axis=0).reset_index(drop=True),\n",
    "    \"lin_predicted_all\": pd.concat([df[\"predicted\"] for df in test_and_preds_all], axis=0).reset_index(drop=True)\n",
    "})\n",
    "\n",
    "lin_df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Find the maximum length among all metric lists\n",
    "max_length = max(\n",
    "    len(mse_list_9), len(mae_list_9), len(mape_list_9), len(r2_list_9),\n",
    "    len(mse_list_9_after), len(mae_list_9_after), len(mape_list_9_after), len(r2_list_9_after),\n",
    "    len(mse_list_all), len(mae_list_all), len(mape_list_all), len(r2_list_all)\n",
    ")\n",
    "\n",
    "# Function to pad lists with NaN values to match the max_length\n",
    "def pad_list(metric_list, max_length):\n",
    "    return metric_list + [np.nan] * (max_length - len(metric_list))\n",
    "\n",
    "# Create a DataFrame to store metrics with padded lists\n",
    "lin_df_metrics = pd.DataFrame({\n",
    "    \"mse_9\": pad_list(mse_list_9, max_length),\n",
    "    \"mae_9\": pad_list(mae_list_9, max_length),\n",
    "    \"mape_9\": pad_list(mape_list_9, max_length),\n",
    "    \"r2_9\": pad_list(r2_list_9, max_length),\n",
    "    \"mse_after\": pad_list(mse_list_9_after, max_length),\n",
    "    \"mae_after\": pad_list(mae_list_9_after, max_length),\n",
    "    \"mape_after\": pad_list(mape_list_9_after, max_length),\n",
    "    \"r2_after\": pad_list(r2_list_9_after, max_length),\n",
    "    \"mse_all\": pad_list(mse_list_all, max_length),\n",
    "    \"mae_all\": pad_list(mae_list_all, max_length),\n",
    "    \"mape_all\": pad_list(mape_list_all, max_length),\n",
    "    \"r2_all\": pad_list(r2_list_all, max_length)\n",
    "})\n",
    "lin_df_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "\n",
    "def run_xgb_model(window_size, test_size, train_data):\n",
    "\n",
    "    n = len(train_data)\n",
    "\n",
    "    # Lists to store metrics and xgb_models\n",
    "    mse_list = []\n",
    "    r2_list = []\n",
    "    mape_list = []\n",
    "    test_and_preds_list = []\n",
    "    mae_list = []\n",
    "\n",
    "    # Sliding window training loop\n",
    "    for start in range(window_size, n, test_size):\n",
    "        training_1 = train_data.iloc[:start]  # Define the training window\n",
    "        dev_1 = train_data.iloc[start:start+test_size]  # Define the next test set\n",
    "\n",
    "        # Create loss indicator for the training data\n",
    "        loss_indicator_for_train = pd.DataFrame(training_1.groupby(['STATE'])['FORECLOSURE_COSTS'].mean())\n",
    "\n",
    "        # Iterate over main columns to calculate mean and merge for training data\n",
    "        loss_indicator_for_training_1 = loss_indicator_for_train.copy()  # Initialize the loss indicator\n",
    "        for col in main_cols:\n",
    "            x = pd.DataFrame(training_1.groupby(['STATE'])[col].mean())\n",
    "            loss_indicator_for_training_1 = pd.merge(loss_indicator_for_training_1, x, how='left', on='STATE')\n",
    "\n",
    "        # Apply the same transformations on both training and test data\n",
    "        X_training_1 = pd.merge(training_1.drop(columns=loss_cols), loss_indicator_for_training_1, how='left', on='STATE')\n",
    "        y_training_1 = training_1['lgd']\n",
    "\n",
    "        X_dev_1 = pd.merge(dev_1.drop(columns=loss_cols), loss_indicator_for_training_1, how='left', on='STATE')\n",
    "        y_dev_1 = dev_1['lgd']\n",
    "\n",
    "        # Convert categorical features using one-hot encoding (excluding 'ZB_DTE' and 'SELLER')\n",
    "        object_cols = X_training_1.select_dtypes(include=['object']).columns.drop(['ZB_DTE', 'SELLER', 'DLQ_STATUS'])\n",
    "        X_training_1 = pd.get_dummies(X_training_1, columns=object_cols, dtype='int')\n",
    "        X_dev_1 = pd.get_dummies(X_dev_1, columns=object_cols, dtype='int')\n",
    "\n",
    "        X_training_1.drop(columns = ['ZB_DTE', 'SELLER', 'DLQ_STATUS'], inplace=True)\n",
    "        X_dev_1.drop(columns = ['ZB_DTE', 'SELLER', 'DLQ_STATUS'], inplace=True)\n",
    "\n",
    "        # Ensure train and test have the same columns after encoding\n",
    "        X_training_1, X_dev_1 = X_training_1.align(X_dev_1, join='left', axis=1, fill_value=0)\n",
    "\n",
    "        # XGBoost xgb_model parameters\n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',  # Using regression as the task is LGD prediction\n",
    "            'n_estimators': 500,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_depth': 10,\n",
    "            'random_state': 42\n",
    "            }\n",
    "\n",
    "        # Initialize and train the XGBoost xgb_model\n",
    "        xgb_model = xgb.XGBRegressor(**params)\n",
    "        xgb_model.fit(X_training_1, y_training_1)\n",
    "\n",
    "        y_pred = xgb_model.predict(X_dev_1)\n",
    "        y_pred_series = pd.Series(y_pred, index=y_dev_1.index)\n",
    "        test_and_preds = pd.concat([y_dev_1, y_pred_series], axis=1)\n",
    "        test_and_preds.columns = ['actual', 'predicted']\n",
    "        test_and_preds_list.append(test_and_preds)\n",
    "\n",
    "        # Calculate MSE and R-squared\n",
    "        mse = mean_squared_error(y_dev_1, y_pred)\n",
    "        r2 = r2_score(y_dev_1, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_dev_1, y_pred)\n",
    "        mae = mean_absolute_error(y_dev_1, y_pred)\n",
    "        \n",
    "        # Store metrics and xgb_model\n",
    "        mse_list.append(mse)\n",
    "        r2_list.append(r2)\n",
    "        mape_list.append(mape)\n",
    "        mae_list.append(mae)\n",
    "\n",
    "        print(f\"Mean Squared Error for this window (start {start}): {mse}\")\n",
    "        print(f\"Mean absolute Error for this window (start {start}): {mae}\")\n",
    "        print(f\"Mean % Error for this window (start {start}): {mape}\")\n",
    "        print(f\"R² for this window (start {start}): {r2}\")\n",
    "\n",
    "    return test_and_preds_list, mse_list, r2_list, mape_list, mae_list, xgb_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_and_preds_list_9, xgb_mse_list_9, xgb_r2_list_9, xgb_mape_list_9, xgb_mae_list_9, xgb_model_9 = run_xgb_model(80000, 20000, train_data_2009)\n",
    "xgb_test_and_preds_list_9_after, xgb_mse_list_9_after, xgb_r2_list_9_after, xgb_mape_list_9_after, xgb_mae_list_9_after, xgb_model_after = run_xgb_model(50000, 50000, train_data_2009_2017)\n",
    "xgb_test_and_preds_all, xgb_mse_list_all, xgb_r2_list_all, xgb_mape_list_all, xgb_mae_list_all, xgb_model_all = run_xgb_model(350000, 50000, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_df_preds = pd.DataFrame({\n",
    "    \"xgb_actual_9\": pd.concat([df[\"actual\"] for df in xgb_test_and_preds_list_9], axis=0).reset_index(drop=True),\n",
    "    \"xgb_predicted_9\": pd.concat([df[\"predicted\"] for df in xgb_test_and_preds_list_9], axis=0).reset_index(drop=True),\n",
    "    \"xgb_actual_after\": pd.concat([df[\"actual\"] for df in xgb_test_and_preds_list_9_after], axis=0).reset_index(drop=True),\n",
    "    \"xgb_predicted_after\": pd.concat([df[\"predicted\"] for df in xgb_test_and_preds_list_9_after], axis=0).reset_index(drop=True),\n",
    "    \"xgb_actual_all\": pd.concat([df[\"actual\"] for df in xgb_test_and_preds_all], axis=0).reset_index(drop=True),\n",
    "    \"xgb_predicted_all\": pd.concat([df[\"predicted\"] for df in xgb_test_and_preds_all], axis=0).reset_index(drop=True)\n",
    "})\n",
    "# Find the maximum length among all metric lists\n",
    "max_length = max(\n",
    "    len(xgb_mse_list_9), len(xgb_mae_list_9), len(xgb_mape_list_9), len(xgb_r2_list_9),\n",
    "    len(xgb_mse_list_9_after), len(xgb_mae_list_9_after), len(xgb_mape_list_9_after), len(xgb_r2_list_9_after),\n",
    "    len(xgb_mse_list_all), len(xgb_mae_list_all), len(xgb_mape_list_all), len(xgb_r2_list_all)\n",
    ")\n",
    "\n",
    "# Function to pad lists with NaN values to match the max_length\n",
    "def pad_list(metric_list, max_length):\n",
    "    return metric_list + [np.nan] * (max_length - len(metric_list))\n",
    "\n",
    "# Create a DataFrame to store metrics with padded lists\n",
    "xgb_df_metrics = pd.DataFrame({\n",
    "   \"xgb_mse_9\": pad_list(xgb_mse_list_9, max_length),\n",
    "   \"xgb_mae_9\": pad_list(xgb_mae_list_9, max_length),\n",
    "   \"xgb_mape_9\": pad_list(xgb_mape_list_9, max_length),\n",
    "    \"xgb_r2_9\": pad_list(xgb_r2_list_9, max_length),\n",
    "   \"xgb_mse_after\": pad_list(xgb_mse_list_9_after, max_length),\n",
    "   \"xgb_mae_after\": pad_list(xgb_mae_list_9_after, max_length),\n",
    "   \"xgb_mape_after\": pad_list(xgb_mape_list_9_after, max_length),\n",
    "    \"xgb_r2_after\": pad_list(xgb_r2_list_9_after, max_length),\n",
    "   \"xgb_mse_all\": pad_list(xgb_mse_list_all, max_length),\n",
    "   \"xgb_mae_all\": pad_list(xgb_mae_list_all, max_length),\n",
    "   \"xgb_mape_all\": pad_list(xgb_mape_list_all, max_length),\n",
    "    \"xgb_r2_all\": pad_list(xgb_r2_list_all, max_length)\n",
    "})\n",
    "xgb_df_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Reset index to avoid potential gaps and ensure a continuous index range\n",
    "lin_df_preds_before = lin_df_preds[['lin_actual_9', 'lin_predicted_9']].dropna().reset_index(drop=True)\n",
    "lin_df_preds_after = lin_df_preds[['lin_actual_after', 'lin_predicted_after']].dropna().reset_index(drop=True)\n",
    "xgb_df_preds_before = xgb_df_preds[['xgb_actual_9', 'xgb_predicted_9']].dropna().reset_index(drop=True)\n",
    "xgb_df_preds_after = xgb_df_preds[['xgb_actual_after', 'xgb_predicted_after']].dropna().reset_index(drop=True)\n",
    "\n",
    "# Plot actual vs. predicted values for both Linear Regression and XGBoost before and after\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10), sharex=True, sharey=True)\n",
    "fig.suptitle('Actual vs. Predicted Values - Linear Regression and XGBoost')\n",
    "\n",
    "# Linear Regression - Before\n",
    "sns.lineplot(data=lin_df_preds_before, x=lin_df_preds_before.index, y='lin_actual_9', ax=axes[0, 0], label=\"Actual\")\n",
    "sns.lineplot(data=lin_df_preds_before, x=lin_df_preds_before.index, y='lin_predicted_9', ax=axes[0, 0], label=\"Predicted\")\n",
    "axes[0, 0].set_title(\"Linear Regression - Before\")\n",
    "\n",
    "# Linear Regression - After\n",
    "sns.lineplot(data=lin_df_preds_after, x=lin_df_preds_after.index, y='lin_actual_after', ax=axes[0, 1], label=\"Actual\")\n",
    "sns.lineplot(data=lin_df_preds_after, x=lin_df_preds_after.index, y='lin_predicted_after', ax=axes[0, 1], label=\"Predicted\")\n",
    "axes[0, 1].set_title(\"Linear Regression - After\")\n",
    "\n",
    "# XGBoost - Before\n",
    "sns.lineplot(data=xgb_df_preds_before, x=xgb_df_preds_before.index, y='xgb_actual_9', ax=axes[1, 0], label=\"Actual\")\n",
    "sns.lineplot(data=xgb_df_preds_before, x=xgb_df_preds_before.index, y='xgb_predicted_9', ax=axes[1, 0], label=\"Predicted\")\n",
    "axes[1, 0].set_title(\"XGBoost - Before\")\n",
    "\n",
    "# XGBoost - After\n",
    "sns.lineplot(data=xgb_df_preds_after, x=xgb_df_preds_after.index, y='xgb_actual_after', ax=axes[1, 1], label=\"Actual\")\n",
    "sns.lineplot(data=xgb_df_preds_after, x=xgb_df_preds_after.index, y='xgb_predicted_after', ax=axes[1, 1], label=\"Predicted\")\n",
    "axes[1, 1].set_title(\"XGBoost - After\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_limits = (-200, 200)  # Set this based on the observed x-axis range\n",
    "y_limits = (0, 0.02)    # Set this based on the observed y-axis range\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Density Estimation - Linear Regression and XGBoost')\n",
    "\n",
    "sns.kdeplot(lin_df_preds['lin_actual_9'], ax=axes[0, 0], label=\"Actual\", shade=True)\n",
    "sns.kdeplot(lin_df_preds['lin_predicted_9'], ax=axes[0, 0], label=\"Predicted\", shade=True)\n",
    "axes[0, 0].set_title(\"Linear Regression - Before\")\n",
    "axes[0, 0].set_xlim(x_limits)\n",
    "axes[0, 0].set_ylim(y_limits)\n",
    "\n",
    "# Plot for Linear Regression - After\n",
    "sns.kdeplot(lin_df_preds['lin_actual_after'], ax=axes[0, 1], label=\"Actual\", shade=True)\n",
    "sns.kdeplot(lin_df_preds['lin_predicted_after'], ax=axes[0, 1], label=\"Predicted\", shade=True)\n",
    "axes[0, 1].set_title(\"Linear Regression - After\")\n",
    "axes[0, 1].set_xlim(x_limits)\n",
    "axes[0, 1].set_ylim(y_limits)\n",
    "\n",
    "# Plot for XGBoost - Before\n",
    "sns.kdeplot(xgb_df_preds['xgb_actual_9'], ax=axes[1, 0], label=\"Actual\", shade=True)\n",
    "sns.kdeplot(xgb_df_preds['xgb_predicted_9'], ax=axes[1, 0], label=\"Predicted\", shade=True)\n",
    "axes[1, 0].set_title(\"XGBoost - Before\")\n",
    "axes[1, 0].set_xlim(x_limits)\n",
    "axes[1, 0].set_ylim(y_limits)\n",
    "\n",
    "# Plot for XGBoost - After\n",
    "sns.kdeplot(xgb_df_preds['xgb_actual_after'], ax=axes[1, 1], label=\"Actual\", shade=True)\n",
    "sns.kdeplot(xgb_df_preds['xgb_predicted_after'], ax=axes[1, 1], label=\"Predicted\", shade=True)\n",
    "axes[1, 1].set_title(\"XGBoost - After\")\n",
    "axes[1, 1].set_xlim(x_limits)\n",
    "axes[1, 1].set_ylim(y_limits)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the metrics DataFrame for easy plotting\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Model\": [\"Linear - Before\", \"Linear - After\", \"XGBoost - Before\", \"XGBoost - After\"],\n",
    "    \"MSE\": [lin_df_metrics[\"mse_9\"].mean(), lin_df_metrics[\"mse_after\"].mean(),\n",
    "            xgb_df_metrics[\"xgb_mse_9\"].mean(), xgb_df_metrics[\"xgb_mse_after\"].mean()],\n",
    "    \"MAE\": [lin_df_metrics[\"mae_9\"].mean(), lin_df_metrics[\"mae_after\"].mean(),\n",
    "            xgb_df_metrics[\"xgb_mae_9\"].mean(), xgb_df_metrics[\"xgb_mae_after\"].mean()],\n",
    "    # \"MAPE\": [lin_df_metrics[\"mape_9\"].mean(), lin_df_metrics[\"mape_after\"].mean(),\n",
    "    #          xgb_df_metrics[\"xgb_mape_9\"].mean(), xgb_df_metrics[\"xgb_mape_after\"].mean()],\n",
    "    \"R2\": [lin_df_metrics[\"r2_9\"].mean(), lin_df_metrics[\"r2_after\"].mean(),\n",
    "           xgb_df_metrics[\"xgb_r2_9\"].mean(), xgb_df_metrics[\"xgb_r2_after\"].mean()]\n",
    "})\n",
    "\n",
    "# Plot each metric\n",
    "metrics_df.set_index(\"Model\")[[\"MAE\", \"R2\"]].plot(kind=\"bar\", subplots=True, layout=(2, 2), figsize=(12, 10), legend=True)\n",
    "plt.suptitle(\"Metric Comparison for Linear Regression and XGBoost Models\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_2009_2017[lin_model_9.feature_names_in_]\n",
    "X_test_2009['STATE_GU'] = 0\n",
    "X_test_2009_2017['MI_TYPE_3.0'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lin_pred_9 = lin_model_9.predict(X_test_2009[lin_model_9.feature_names_in_])\n",
    "mse_lin_9 = mean_squared_error(y_test_2009, y_lin_pred_9)\n",
    "r2_lin_9 = r2_score(y_test_2009, y_lin_pred_9)\n",
    "mape_lin_9 = mean_absolute_percentage_error(y_test_2009, y_lin_pred_9)\n",
    "mae_lin_9 = mean_absolute_error(y_test_2009, y_lin_pred_9)\n",
    "\n",
    "# Create DataFrame for predictions \"before 2009\"\n",
    "lin_test_and_preds_9 = pd.DataFrame({\n",
    "    'actual_9': y_test_2009,\n",
    "    'predicted_lin_9': y_lin_pred_9\n",
    "})\n",
    "\n",
    "print(\"Linear Regression Metrics - Before 2009:\")\n",
    "print(f\"MSE: {mse_lin_9}, R²: {r2_lin_9}, MAPE: {mape_lin_9}, MAE: {mae_lin_9}\")\n",
    "\n",
    "y_lin_pred_after = lin_model_after.predict(X_test_2009_2017[lin_model_after.feature_names_in_])\n",
    "mse_lin_after = mean_squared_error(y_test_2009_2017, y_lin_pred_after)\n",
    "r2_lin_after = r2_score(y_test_2009_2017, y_lin_pred_after)\n",
    "mape_lin_after = mean_absolute_percentage_error(y_test_2009_2017, y_lin_pred_after)\n",
    "mae_lin_after = mean_absolute_error(y_test_2009_2017, y_lin_pred_after)\n",
    "\n",
    "# Create DataFrame for predictions \"before 2009\"\n",
    "lin_test_and_preds_after = pd.DataFrame({\n",
    "    'actual_after': y_test_2009_2017,\n",
    "    'predicted_lin_after': y_lin_pred_after\n",
    "})\n",
    "\n",
    "print(\"Linear Regression Metrics - After 2009:\")\n",
    "print(f\"MSE: {mse_lin_after}, R²: {r2_lin_after}, MAPE: {mape_lin_after}, MAE: {mae_lin_after}\")\n",
    "\n",
    "y_lin_pred_all = lin_model_all.predict(X_test[lin_model_all.feature_names_in_])\n",
    "mse_lin_all = mean_squared_error(y_test_all, y_lin_pred_all)\n",
    "r2_lin_all = r2_score(y_test_all, y_lin_pred_all)\n",
    "mape_lin_all = mean_absolute_percentage_error(y_test_all, y_lin_pred_all)\n",
    "mae_lin_all = mean_absolute_error(y_test_all, y_lin_pred_all)\n",
    "\n",
    "# Create DataFrame for predictions \"before 2009\"\n",
    "lin_test_and_preds_all = pd.DataFrame({\n",
    "    'actual_all': y_test_all,\n",
    "    'predicted_lin_all': y_lin_pred_all\n",
    "})\n",
    "\n",
    "print(\"linear Regression Metrics - all data:\")\n",
    "print(f\"MSE: {mse_lin_all}, R²: {r2_lin_all}, MAPE: {mape_lin_all}, MAE: {mae_lin_all}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_xgb_pred_9 = xgb_model_9.predict(X_test_2009[xgb_model_9.feature_names_in_])\n",
    "mse_xgb_9 = mean_squared_error(y_test_2009, y_xgb_pred_9)\n",
    "r2_xgb_9 = r2_score(y_test_2009, y_xgb_pred_9)\n",
    "mape_xgb_9 = mean_absolute_percentage_error(y_test_2009, y_xgb_pred_9)\n",
    "mae_xgb_9 = mean_absolute_error(y_test_2009, y_xgb_pred_9)\n",
    "\n",
    "# Create DataFrame for predictions \"before 2009\"\n",
    "xgb_test_and_preds_9 = pd.DataFrame({\n",
    "    'actual_9': y_test_2009,\n",
    "    'predicted_xgb_9': y_xgb_pred_9\n",
    "})\n",
    "\n",
    "print(\"xgbear Regression Metrics - Before 2009:\")\n",
    "print(f\"MSE: {mse_xgb_9}, R²: {r2_xgb_9}, MAPE: {mape_xgb_9}, MAE: {mae_xgb_9}\")\n",
    "\n",
    "y_xgb_pred_after = xgb_model_after.predict(X_test_2009_2017[xgb_model_after.feature_names_in_])\n",
    "mse_xgb_after = mean_squared_error(y_test_2009_2017, y_xgb_pred_after)\n",
    "r2_xgb_after = r2_score(y_test_2009_2017, y_xgb_pred_after)\n",
    "mape_xgb_after = mean_absolute_percentage_error(y_test_2009_2017, y_xgb_pred_after)\n",
    "mae_xgb_after = mean_absolute_error(y_test_2009_2017, y_xgb_pred_after)\n",
    "\n",
    "# Create DataFrame for predictions \"before 2009\"\n",
    "xgb_test_and_preds_after = pd.DataFrame({\n",
    "    'actual_after': y_test_2009_2017,\n",
    "    'predicted_xgb_after': y_xgb_pred_after\n",
    "})\n",
    "\n",
    "print(\"xgbear Regression Metrics - After 2009:\")\n",
    "print(f\"MSE: {mse_xgb_after}, R²: {r2_xgb_after}, MAPE: {mape_xgb_after}, MAE: {mae_xgb_after}\")\n",
    "\n",
    "y_xgb_pred_all = xgb_model_all.predict(X_test[xgb_model_all.feature_names_in_])\n",
    "mse_xgb_all = mean_squared_error(y_test_all, y_xgb_pred_all)\n",
    "r2_xgb_all = r2_score(y_test_all, y_xgb_pred_all)\n",
    "mape_xgb_all = mean_absolute_percentage_error(y_test_all, y_xgb_pred_all)\n",
    "mae_xgb_all = mean_absolute_error(y_test_all, y_xgb_pred_all)\n",
    "\n",
    "# Create DataFrame for predictions \"before 2009\"\n",
    "xgb_test_and_preds_all = pd.DataFrame({\n",
    "    'actual_all': y_test_all,\n",
    "    'predicted_xgb_all': y_xgb_pred_all\n",
    "})\n",
    "\n",
    "print(\"xgb Regression Metrics - all data:\")\n",
    "print(f\"MSE: {mse_xgb_all}, R²: {r2_xgb_all}, MAPE: {mape_xgb_all}, MAE: {mae_xgb_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have calculated the metrics as follows:\n",
    "# Linear Regression - Before 2009\n",
    "mse_lin_9, r2_lin_9, mape_lin_9, mae_lin_9\n",
    "\n",
    "# Linear Regression - After 2009\n",
    "mse_lin_after, r2_lin_after, mape_lin_after, mae_lin_after\n",
    "\n",
    "# XGBoost - Before 2009\n",
    "mse_xgb_9, r2_xgb_9, mape_xgb_9, mae_xgb_9\n",
    "\n",
    "# XGBoost - After 2009\n",
    "mse_xgb_after, r2_xgb_after, mape_xgb_after, mae_xgb_after\n",
    "\n",
    "# Prepare data for R² and MAE\n",
    "r2_values = [r2_lin_9, r2_lin_after, r2_xgb_9, r2_xgb_after]\n",
    "mae_values = [mae_lin_9, mae_lin_after, mae_xgb_9, mae_xgb_after]\n",
    "\n",
    "# Labels for the bars\n",
    "labels = ['Linear - Before 2009', 'Linear - After 2009', 'XGBoost - Before 2009', 'XGBoost - After 2009']\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.4\n",
    "index = np.arange(len(labels))\n",
    "\n",
    "# Plotting R² and MAE on separate subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# R² subplot\n",
    "axes[0].bar(index, r2_values, bar_width, color='skyblue')\n",
    "axes[0].set_xlabel('Model and Period')\n",
    "axes[0].set_ylabel('R²')\n",
    "axes[0].set_title('R² Comparison')\n",
    "axes[0].set_xticks(index)\n",
    "axes[0].set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "\n",
    "# MAE subplot\n",
    "axes[1].bar(index, mae_values, bar_width, color='salmon')\n",
    "axes[1].set_xlabel('Model and Period')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('MAE Comparison')\n",
    "axes[1].set_xticks(index)\n",
    "axes[1].set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import xgboost as xgb  # assuming you have xgboost installed\n",
    "\n",
    "# # Assuming lin_model_all and xgb_model_all are the trained models for Linear Regression and XGBoost, respectively.\n",
    "\n",
    "# ### 1. Linear Regression Feature Importances\n",
    "# # Get the absolute values of coefficients\n",
    "# lin_coef_all = pd.Series(np.abs(lin_model_all.coef_), index=lin_model_all.feature_names_in_)\n",
    "# lin_coef_all = lin_coef_all.sort_values(ascending=False)\n",
    "\n",
    "# ### 2. XGBoost Feature Importances\n",
    "# # Get feature importances from the trained XGBoost model\n",
    "# xgb_importance_all = pd.Series(xgb_model_all.feature_importances_, index=xgb_model_all.feature_names_in_)\n",
    "# xgb_importance_all = xgb_importance_all.sort_values(ascending=False)\n",
    "# xgb_importance_all_gain = pd.Series(xgb_model_all.get_booster().get_score(importance_type='weight'), index=xgb_model_after.feature_names_in_)\n",
    "# xgb_importance_all_gain = xgb_importance_all_gain.sort_values(ascending=False)\n",
    "\n",
    "# ### Plotting Feature Importances\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(14, 6))\n",
    "# fig.suptitle(\"Feature Importances for Linear Regression and XGBoost Models\")\n",
    "\n",
    "# # Linear Regression plot\n",
    "# axes[0].barh(lin_coef_all.index[:20], lin_coef_all.values[:20], color='skyblue')\n",
    "# axes[0].invert_yaxis()\n",
    "# axes[0].set_title('Top 20 Feature Importances - Linear Regression')\n",
    "# axes[0].set_xlabel('Absolute Coefficient Value')\n",
    "\n",
    "# # XGBoost plot\n",
    "# axes[1].barh(xgb_importance_all.index[:20], xgb_importance_all.values[:20], color='salmon')\n",
    "# axes[1].invert_yaxis()\n",
    "# axes[1].set_title('Top 20 Feature Importances - XGBoost')\n",
    "# axes[1].set_xlabel('Importance Score')\n",
    "\n",
    "# axes[2].barh(xgb_importance_all_gain.index[:20], xgb_importance_all_gain.values[:20], color='salmon')\n",
    "# axes[2].invert_yaxis()\n",
    "# axes[2].set_title('Top 20 Feature Importances - XGBoost')\n",
    "# axes[2].set_xlabel('Importance Score')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_test_xgb = X_test[xgb_model_all.feature_names_in_]\n",
    "X_test_lin = X_test[lin_model_all.feature_names_in_]\n",
    "# SHAP values for XGBoost\n",
    "explainer = shap.Explainer(xgb_model_all, X_test_xgb)\n",
    "shap_values_xgb = explainer(X_test_xgb)\n",
    "\n",
    "# SHAP summary plot for XGBoost\n",
    "shap.summary_plot(shap_values_xgb, X_test_xgb, plot_type=\"bar\")  # Importance by mean absolute SHAP value\n",
    "\n",
    "# Permutation Importance for Linear Regression\n",
    "perm_importance_lin = permutation_importance(lin_model_all, X_test_lin, y_test_all, scoring=make_scorer(mean_absolute_error, greater_is_better=False), n_repeats=20, random_state=0)\n",
    "scoring=make_scorer(mean_squared_error, greater_is_better=False)\n",
    "# Plot permutation importance for linear regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(X_test_lin.columns, perm_importance_lin.importances_mean)\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "plt.title(\"Feature Importance - Linear Regression\")\n",
    "plt.show()\n",
    "\n",
    "# Permutation Importance for XGBoost\n",
    "perm_importance_xgb = permutation_importance(xgb_model_all, X_test_xgb, y_test_all,scoring=make_scorer(mean_absolute_error, greater_is_better=False), n_repeats=20, random_state=0)\n",
    "\n",
    "# Plot permutation importance for XGBoost\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(X_test_xgb.columns, perm_importance_xgb.importances_mean)\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "plt.title(\"Feature Importance - XGBoost\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X_test_lin and X_test_xgb contain feature names for linear regression and XGBoost respectively\n",
    "# And perm_importance_lin and perm_importance_xgb are the permutation importance dictionaries for each model\n",
    "\n",
    "# Create DataFrames for linear regression and XGBoost importances\n",
    "feature_names_lin = X_test_lin.columns  # Adjust this if needed\n",
    "feature_names_xgb = X_test_xgb.columns  # Adjust this if needed\n",
    "\n",
    "importance_df_lin = pd.DataFrame({\n",
    "    'feature': feature_names_lin,\n",
    "    'importance_mean': perm_importance_lin['importances_mean'],\n",
    "    'importance_std': perm_importance_lin['importances_std']\n",
    "})\n",
    "\n",
    "importance_df_xgb = pd.DataFrame({\n",
    "    'feature': feature_names_xgb,\n",
    "    'importance_mean': perm_importance_xgb['importances_mean'],\n",
    "    'importance_std': perm_importance_xgb['importances_std']\n",
    "})\n",
    "\n",
    "# Sort by mean importance and select the top 20 for each model\n",
    "top_20_features_lin = importance_df_lin.sort_values(by='importance_mean', ascending=False).head(20)\n",
    "top_20_features_xgb = importance_df_xgb.sort_values(by='importance_mean', ascending=False).head(20)\n",
    "\n",
    "# Plot side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 10), sharey=True)\n",
    "fig.suptitle(\"Top 20 Feature Importances Comparison - Linear Regression vs XGBoost\")\n",
    "\n",
    "# # Plot for Linear Regression\n",
    "axes[0].barh(top_20_features_lin['feature'], top_20_features_lin['importance_mean'], xerr=top_20_features_lin['importance_std'], color='skyblue')\n",
    "axes[0].set_xlabel(\"Mean Permutation Importance\")\n",
    "axes[0].set_title(\"Linear Regression\")\n",
    "axes[0].invert_yaxis()  # Invert y-axis to have the highest importance on top\n",
    "\n",
    "# Plot for XGBoost\n",
    "axes[1].barh(top_20_features_xgb['feature'], top_20_features_xgb['importance_mean'], xerr=top_20_features_xgb['importance_std'], color='salmon')\n",
    "axes[1].set_xlabel(\"Mean Permutation Importance\")\n",
    "axes[1].set_title(\"XGBoost\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_xgb.sort_values(by='importance_mean', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_importance_all = pd.Series(xgb_model_all.feature_importances_, index=xgb_model_all.feature_names_in_)\n",
    "xgb_importance_all = xgb_importance_all.sort_values(ascending=False)\n",
    "\n",
    "xgb_importance_all.index[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = top_20_features_xgb.merge(top_20_features_lin, how='left', on='feature')['feature'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb_model_all)\n",
    "shap_values = explainer.shap_values(X_test[xgb_model_all.feature_names_in_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(shap_values)\n",
    "remaining_shap_dependency_features = list(set(top_features) - set(xgb_importance_all.index[:20]))\n",
    "remaining_shap_dependency_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Assuming shap_values, X_test, and xgb_model_all are already defined\n",
    "# For regression, no need to select first element\n",
    "# shap_values = shap_values[0]  # Remove this line for regression\n",
    "\n",
    "# Ensure we're using the correct features\n",
    "X_test = X_test[xgb_model_all.feature_names_in_]\n",
    "\n",
    "# Create directory for saving plots\n",
    "if not os.path.exists('shap_interaction_plots'):\n",
    "    os.makedirs('shap_interaction_plots_2')\n",
    "\n",
    "# Loop through top 20 features\n",
    "for main_feature in remaining_shap_dependency_features:\n",
    "    # Loop through all features for interactions\n",
    "    for inner_feature in xgb_importance_all.index:\n",
    "        if main_feature != inner_feature:  # Skip self-interactions\n",
    "            try:\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
    "                plt.suptitle(f'SHAP Dependence Plots for {main_feature}')\n",
    "\n",
    "                # Plot 1: Auto-detected interaction\n",
    "                plt.sca(axes[0])\n",
    "                shap.dependence_plot(\n",
    "                    ind=main_feature,  # Added 'ind=' for clarity\n",
    "                    shap_values=shap_values,\n",
    "                    features=X_test,\n",
    "                    interaction_index=inner_feature,\n",
    "                    show=False\n",
    "                )\n",
    "                axes[1].set_title(f'interaction_/{main_feature}_vs_{inner_feature}')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Save the plot\n",
    "                plt.savefig(f'shap_interaction_plots/{main_feature}_vs_{inner_feature}.png', \n",
    "                           bbox_inches='tight', \n",
    "                           dpi=300)\n",
    "                plt.close(fig)  # Close the figure to free memory\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error plotting {main_feature} vs {inner_feature}: {str(e)}\")\n",
    "                plt.close(fig)  # Make sure to close figure even if error occurs\n",
    "\n",
    "print(\"Analysis complete. Check the 'shap_interaction_plots' directory for results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_paid_vs_lgd = pd.DataFrame(data.groupby(['LAST_PAID_INSTALLMENT_DATE_year'])['lgd'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = pd.DataFrame(data.groupby(['ORIG_UPB', 'LAST_UPB', 'LAST_PAID_INSTALLMENT_DATE_year', 'CPIAUCNS', 'OLTV', 'OCC_STAT', 'MI_TYPE', 'RE_PROCS_FLAG', 'PURPOSE', 'HPI'])['lgd'].median())\n",
    "x = pd.DataFrame(data.groupby(['HPI'])['lgd'].median())\n",
    "\n",
    "x.reset_index(inplace=True), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.sort_values(by = 'lgd', ascending = False)\n",
    "num_bins = 20\n",
    "bin_edges = pd.cut(data['HPI'], bins=num_bins)\n",
    "\n",
    "# Assign the bins to a new column\n",
    "data['HPI_bins'] = bin_edges\n",
    "\n",
    "# Calculate the mean lgd for each bin\n",
    "mean_lgd_per_bin = pd.DataFrame(data.groupby('HPI_bins')['lgd'].mean())\n",
    "\n",
    "mean_lgd_per_bin.sort_values(by='lgd').plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=x['lgd'], y=x['HPI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a scatter plot for each year, with a regression line\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lmplot(data=x, x='HPI', y='lgd', hue='OCC_STAT', aspect=2, height=6, markers='o')\n",
    "\n",
    "plt.title('Effect of CPIAUCNS on LGD by Year')\n",
    "plt.xlabel('OCC_STAT')\n",
    "plt.ylabel('LGD')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
